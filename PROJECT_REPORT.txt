================================================================================
                    HATE SPEECH DETECTION PROJECT REPORT
================================================================================

Project Overview:
-----------------
This project implements a machine learning-based Hate Speech Detection API
using FastAPI. The system can classify text as either "hate speech" or "normal"
using various ML algorithms with comprehensive text preprocessing and evaluation
capabilities.

Project Structure:
------------------
- main.py: FastAPI application with REST endpoints
- ml_service.py: Core ML functionality (training, prediction, preprocessing)
- models.py: Pydantic models for API request/response validation
- config.py: Configuration settings, dataset URLs, and sample data
- global_state.py: Global state management for model and metrics
- test_predict.py: Testing script for API predictions
- requirement.txt: Project dependencies

Key Features Implemented:
-------------------------

1. Machine Learning Models:
   - Support for 4 algorithms:
     * Naive Bayes (MultinomialNB)
     * Logistic Regression (default, with class balancing)
     * Support Vector Machine (LinearSVC)
     * Random Forest Classifier
   - Automatic class weight balancing for imbalanced datasets
   - Optional hyperparameter tuning via GridSearchCV

2. Text Preprocessing:
   - Lowercase conversion
   - URL removal
   - User mention (@username) removal
   - Hashtag normalization (keeps word, removes #)
   - Special character cleaning
   - Whitespace normalization
   - Integrated into ML pipeline for automatic preprocessing

3. Feature Engineering:
   - TF-IDF vectorization with advanced parameters:
     * 10,000 max features
     * N-gram range: (1, 3) - unigrams, bigrams, trigrams
     * Sublinear TF scaling
     * L2 normalization
     * Document frequency filtering (min_df=2, max_df=0.95)

4. API Endpoints:
   - GET  /              - API information and available endpoints
   - GET  /health        - Health check endpoint
   - GET  /model-info    - Current model metrics and status
   - GET  /evaluate      - Detailed evaluation metrics (accuracy, precision, recall, F1)
   - GET  /test-results  - View predictions on test set
   - GET  /test-sample   - Random samples from test set
   - GET  /datasets      - List available datasets
   - POST /predict       - Single text prediction
   - POST /batch-predict - Batch prediction (up to 100 texts)
   - POST /train         - Train model with specified dataset and algorithm

5. Dataset Support:
   - Twitter Hate Speech Dataset (Davidson et al.) - ~24k tweets
   - Sample dataset (30 examples) for testing
   - Custom CSV dataset loading from URL
   - Automatic train/test split (default 80/20, stratified)

6. Model Evaluation:
   - Comprehensive metrics tracking:
     * Accuracy
     * Precision
     * Recall
     * F1 Score
     * Confusion Matrix
   - Test set predictions stored for analysis
   - Classification reports for detailed performance analysis

7. Additional Features:
   - Automatic model training on API startup
   - Global state management for model persistence
   - Error handling and logging
   - Confidence scores for predictions
   - Support for models without predict_proba (SVM fallback)

Technical Implementation Details:
----------------------------------

- Framework: FastAPI (Python web framework)
- ML Library: scikit-learn
- Data Processing: pandas, numpy
- Text Vectorization: TF-IDF with advanced parameters
- Model Pipeline: sklearn Pipeline with preprocessing transformer
- State Management: Global state module for model and metrics storage
- Logging: Comprehensive logging throughout the application

Model Training Process:
-----------------------
1. Dataset loading (from URL or sample data)
2. Train/test split (stratified, default 80/20)
3. Text preprocessing (if enabled)
4. TF-IDF feature extraction
5. Model training with selected algorithm
6. Evaluation on test set
7. Metrics calculation and storage
8. Model persistence in global state

Prediction Workflow:
--------------------
1. Text input received via API
2. Automatic preprocessing (if enabled in pipeline)
3. Feature extraction (TF-IDF)
4. Model prediction
5. Confidence score calculation
6. Response formatting with label and confidence

Dependencies:
-------------
- fastapi
- uvicorn[standard]
- scikit-learn
- pandas
- numpy
- requests

Current Status:
---------------
The project is fully functional with:
- Complete API implementation
- Multiple ML algorithm support
- Comprehensive text preprocessing
- Model evaluation and metrics
- Test script for API interaction
- Error handling and logging

The system automatically trains a Logistic Regression model on startup using
the Twitter hate speech dataset, and provides a RESTful API for predictions
and model management.

================================================================================
Report Generated: Project implementation complete
================================================================================

